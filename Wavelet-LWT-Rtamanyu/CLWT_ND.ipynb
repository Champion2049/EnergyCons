{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fd15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from itertools import product # Used for generating 'L'/'H' combinations for N-D sub-bands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5a559b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data: [7.343 8.013 8.293 ... 9.517 9.46  9.309]\n",
      "Decomposition Levels: 4\n",
      "------------------------------\n",
      "\n",
      "--- Decomposition Results ---\n",
      "Final LL (Approximation) Sub-band:\n",
      "[ 9.59125   10.6860625  8.7323125  9.1955625  8.441125   8.221375\n",
      "  7.8479375  7.1490625  6.962125   6.2249375  5.7710625  7.5245\n",
      "  8.771875   7.39875    5.4121875  5.01975    6.3794375  7.757\n",
      "  7.014      8.0031875 12.9966875 12.62925   13.577125  13.8368125\n",
      " 18.9803125 12.7923125 11.0743125  9.254     12.215875  12.348125\n",
      "  9.912375   9.9709375  8.8355625  7.166125   5.9406875  6.649\n",
      "  5.9321875  6.913875   8.3043125  8.69575    8.0646875  6.833\n",
      "  6.2956875  6.8020625  8.239625   9.698625  10.1946875 10.96275\n",
      " 14.1834375 14.7228125 12.446125  16.06      17.58275   19.3255625\n",
      " 15.699     11.9244375 19.9943125 14.2140625 13.494     10.1895625\n",
      " 11.451625  11.2745625 11.816375  10.725625  10.8483125 12.2059375\n",
      " 13.195     13.2115625 13.4651875 11.71325    8.3608125  5.138375\n",
      "  2.4628125  0.8096875  1.44925    0.8485     1.0966875  2.0223125\n",
      "  3.8060625  5.321375   7.9545     7.6331875  6.8261875  7.086875\n",
      "  8.72225    8.28175    7.776      4.6365625  2.14025    6.688875\n",
      "  9.892125  12.2110625 12.5753125 11.5978125  7.844375   5.9141875\n",
      "  5.4953125  4.2211875  3.4524375  1.053625   0.8139375  3.2373125\n",
      "  6.0991875  9.39625    6.1274375  5.358375   5.4025625  7.43\n",
      "  7.404375   5.323375   5.853125   6.2010625  6.08125    6.979375\n",
      "  5.918375   3.4605     1.4584375  3.2375625  8.0986875  8.4725\n",
      "  7.899375   6.9305     6.4445     6.8956875  6.9961875  4.847625\n",
      "  6.44825    6.585125   6.3471875  5.9299375  9.5573125 10.15225\n",
      " 12.171625  15.6380625 16.618375  16.9694375 17.70125   16.9445\n",
      " 17.57775   16.4970625 14.49      14.0131875 12.7626875 11.459375\n",
      "  9.9601875 10.9733125  9.3596875 10.0745    10.9531875 11.7328125\n",
      " 10.1074375 10.867375  14.2278125 18.4664375 18.4938125 18.081125\n",
      " 16.109875  16.2013125 17.0848125 17.2665    15.733125  12.76775\n",
      " 15.002625  12.498625   9.367625   6.6320625  7.1924375  9.61075\n",
      "  9.395      6.637125   1.11825    6.8939375  8.64575    7.3805625\n",
      "  5.6779375  5.5344375  5.643125  10.625375  12.381125  11.7125\n",
      " 14.0810625 16.1351875 15.2634375 13.6935    12.8450625 12.3105\n",
      " 11.7410625 14.1031875 13.6868125 11.0593125 12.5166875 12.17325\n",
      "  8.8615625  8.00925    8.141375   9.37475    6.263625   4.286625\n",
      "  4.22325    3.6158125  4.37875    6.05875    5.9341875  5.1425\n",
      "  3.833125   0.7955     1.5961875  2.712      2.6765625  3.5923125\n",
      "  6.2548125  6.0411875  3.1241875  4.9028125  7.0406875  7.31425\n",
      "  7.424125   9.5751875 10.8994375 13.1485625 14.235125  11.7996875\n",
      " 10.9831875  8.8525    11.098875  10.1559375  9.1816875 10.708875\n",
      " 10.753875  11.4125    11.808625  14.0464375 14.7594375 17.1355625\n",
      " 16.7075    20.3680625 17.0715    16.4064375 17.21025   17.955625\n",
      " 19.17275   19.2585625 18.1360625 16.1090625 15.3093125 13.720125\n",
      " 13.47125   10.1609375  7.8155     8.6610625  7.0900625  4.257\n",
      "  5.081      6.3346875  7.31175    7.299375   6.0844375  6.108875\n",
      "  8.7258125  8.3795     9.0285625]\n",
      "  H_L1 Detail:\n",
      "[ 0.67   0.457  0.235 ...  0.106  0.09  -0.151]\n",
      "  H_L2 Detail:\n",
      "[ 0.8435  0.0845  0.647  ...  0.2315  0.1375 -0.0875]\n",
      "  H_L3 Detail:\n",
      "[ 1.12100e+00  1.24450e+00 -3.39750e-01 -9.15500e-01 -1.76250e-01\n",
      "  2.50000e-02  4.81250e-01  2.97500e-01 -3.58750e-01 -1.69125e+00\n",
      "  1.62800e+00 -3.25000e-02 -6.60500e-01  1.17250e-01 -4.00000e-01\n",
      "  2.75000e-03 -4.00500e-01  1.06150e+00 -1.08750e+00 -1.99750e-01\n",
      " -1.39250e-01  2.80000e-01  7.42500e-01  7.86000e-01 -8.25000e-02\n",
      " -2.06500e-01  1.00000e-01 -1.58950e+00  1.35750e-01 -5.03500e-01\n",
      "  3.40500e-01  1.56000e-01  3.02500e-01  1.55250e-01  5.04250e-01\n",
      "  1.87250e-01 -1.07200e+00  3.26500e-01 -6.70000e-02  1.13325e+00\n",
      "  1.72975e+00  1.78450e+00 -8.10000e-01 -1.62400e+00  2.48800e+00\n",
      " -1.02500e-01  4.92500e-02  1.20650e+00  2.90050e+00 -8.41750e-01\n",
      " -6.50000e+00 -1.96775e+00  1.06000e+00  2.50000e-04 -1.35375e+00\n",
      "  7.76250e-01  1.63550e+00 -3.22500e-01 -9.25000e-02 -6.93500e-01\n",
      " -9.10750e-01 -3.41250e-01  2.80750e-01  1.56500e-01 -2.47250e-01\n",
      " -2.16000e-01 -5.65750e-01 -5.82250e-01 -2.09000e-01  1.27500e-02\n",
      "  3.89750e-01 -4.76750e-01 -4.38500e-01  2.26250e-01  6.04750e-01\n",
      "  1.03250e-01  3.82250e-01  4.79500e-01 -3.91000e-01 -7.25000e-02\n",
      " -7.70000e-02 -6.63250e-01  9.02500e-02 -7.67750e-01  1.91000e-01\n",
      " -1.83250e-01  1.11850e+00  6.96250e-01 -4.37500e-02  1.85750e-01\n",
      "  2.16500e-01 -6.00000e-03  6.31750e-01 -4.75000e-02  4.74500e-01\n",
      "  1.63350e+00  1.61500e-01  6.31750e-01  2.43250e-01 -1.43500e+00\n",
      " -6.24150e+00  4.13300e+00 -1.13750e-01  5.72250e-01 -1.00000e-02\n",
      " -2.10500e-01  1.28300e+00  6.52250e-01 -2.42525e+00 -4.06275e+00\n",
      "  4.10750e-01  1.17200e+00  1.66900e+00 -2.41625e+00 -2.07375e+00\n",
      " -5.12000e-01  1.37400e+00 -1.65600e+00 -9.57250e-01  1.38400e+00\n",
      "  7.42500e-01  3.72500e-01 -6.60000e-01  3.57500e-02  1.27000e-01\n",
      " -3.08500e-01 -1.02000e-01  6.00000e-01  1.83000e-01 -1.02525e+00\n",
      "  1.40900e+00 -1.12250e-01  4.14000e-01 -1.15000e-01  2.01250e-01\n",
      "  2.97500e-01  4.50000e-02 -3.66250e-01 -7.27250e-01 -8.56750e-01\n",
      " -5.61250e-01 -8.46000e-01 -9.73250e-01 -1.12675e+00 -1.68250e-01\n",
      " -1.45000e+00 -3.02750e-01  7.18500e-01  4.62500e-02 -1.82250e-01\n",
      " -2.52000e-01 -7.25000e-02 -4.81250e-01  1.38100e+00 -8.91500e-01\n",
      "  1.57225e+00  4.78250e-01 -1.05450e+00  1.27525e+00  1.36275e+00\n",
      "  4.05500e-01  2.11700e+00 -1.05700e+00  1.22525e+00  1.86750e-01\n",
      " -7.89000e-01  1.48500e+00 -8.43000e-01  2.03100e+00 -6.92500e-01\n",
      "  3.85500e-01 -9.95500e-01  2.60250e-01 -3.70250e-01 -1.42450e+00\n",
      " -6.85750e-01 -3.22000e-01  1.39250e+00  1.54625e+00 -5.46750e-01\n",
      "  2.09300e+00  4.32500e-01  2.34750e-01  2.43500e-01 -1.55000e-01\n",
      " -9.82500e-02 -3.77000e-01 -7.37750e-01 -4.62500e-01 -2.82800e+00\n",
      "  4.76250e-01 -7.84500e-01  8.08500e-01 -5.34750e-01  1.57750e-01\n",
      " -8.78000e-01  6.97500e-02  1.21000e-01 -1.80025e+00  3.44750e-01\n",
      "  1.95250e-01  3.06000e-01  1.46625e+00 -3.11000e-01  8.31750e-01\n",
      "  4.22600e+00 -5.93750e-01 -8.94750e-01 -8.20000e-01 -8.02500e-02\n",
      "  1.00250e-01 -4.72500e-02 -3.17250e-01  3.35000e-01  1.03625e+00\n",
      " -4.47250e-01  3.45000e-01 -1.27800e+00  1.37250e-01  4.68250e-01\n",
      "  7.67500e-02  2.27250e-01 -5.00000e-03 -2.86250e-01  5.10000e-01\n",
      " -4.21000e-01  1.97750e-01  2.66250e-01 -6.87750e-01 -4.22250e-01\n",
      " -1.18325e+00 -3.56250e-01 -7.16500e-01 -8.92500e-02  1.21200e+00\n",
      "  6.15750e-01  2.30950e+00  4.37500e-02  3.22750e-01 -3.72750e-01\n",
      " -2.15500e-01 -3.38500e-01 -3.64500e-01  2.23500e-01 -1.59250e-01\n",
      "  1.43425e+00 -1.62475e+00  6.00000e-03  1.65250e-01 -7.59500e-01\n",
      " -1.06200e+00  2.02850e+00 -8.25000e-02  1.13500e+00 -9.41750e-01\n",
      " -9.52500e-02  2.78750e-01 -5.05000e-01 -3.16250e-01  1.06700e+00\n",
      "  1.28225e+00  2.25000e-02  1.98500e-01  7.64000e-01  1.08200e+00\n",
      " -1.57500e+00  1.96825e+00 -2.31000e-01 -5.28750e-01  4.04750e-01\n",
      "  2.47500e-01 -3.14250e-01  6.12500e-01 -2.29000e-01 -4.53500e-01\n",
      "  3.53500e-01  9.01500e-01  5.21500e-01 -6.87250e-01 -8.62500e-01\n",
      " -6.71250e-01 -3.27500e-02  2.10500e-01  9.92500e-02 -7.00250e-01\n",
      " -3.58500e-01 -2.50750e-01  4.27500e-02 -4.58250e-01 -1.22000e-01\n",
      "  5.83000e-01 -1.37775e+00 -5.70500e-01 -1.42500e-02 -7.07500e-02\n",
      "  9.27500e-02  2.53000e-01  1.15675e+00 -3.38000e-01 -8.00750e-01\n",
      " -4.88750e-01  2.13500e-01  8.97000e-01 -2.29000e-01  1.87825e+00\n",
      "  8.37500e-01  8.07250e-01 -1.83500e-01  1.05000e+00  7.29750e-01\n",
      " -3.34000e-01 -1.18700e+00 -8.86500e-01  7.33000e-01  8.90000e-01\n",
      " -1.35975e+00  4.61250e-01 -8.44500e-01  7.24000e-01 -3.90000e-02\n",
      " -8.56750e-01 -8.28750e-01 -7.23500e-01  1.11000e-01  1.25950e+00\n",
      " -3.08500e-01 -2.14325e+00 -7.00250e-01 -1.12500e-01 -9.00500e-01\n",
      " -8.91250e-01 -3.34000e-01  2.70500e-01  1.20075e+00  5.66000e-01\n",
      " -1.36900e+00  3.18250e-01 -4.32250e-01 -9.56250e-01 -1.87775e+00\n",
      " -1.11375e+00  4.33250e-01  3.03200e+00  3.80750e-01 -4.70750e-01\n",
      " -3.47750e-01 -6.65000e-02 -6.72250e-01 -6.75000e-01  6.16250e-01\n",
      " -7.65750e-01 -7.85000e-01  3.93750e-01  1.97925e+00  1.19025e+00\n",
      "  1.21425e+00 -1.86750e-01 -4.80750e-01 -3.64500e-01  1.08450e+00\n",
      " -1.59000e-01  1.29875e+00 -2.62500e-01 -3.87500e-02 -4.43500e-01\n",
      " -7.57250e-01 -2.33750e-01 -1.71750e-01  3.80000e-02 -1.11525e+00\n",
      "  8.12250e-01  6.70250e-01 -1.11450e+00  7.12750e-01  3.51750e-01\n",
      " -2.99000e-01  1.25000e-03  2.72000e-01 -1.78225e+00  1.20600e+00\n",
      "  1.10400e+00 -6.06250e-01  5.25750e-01 -1.01675e+00 -1.97125e+00\n",
      " -1.40500e-01  6.24250e-01 -1.48425e+00  3.67250e-01  7.32250e-01\n",
      " -3.58500e-01 -2.16000e-01 -8.84500e-01 -7.77500e-01 -5.00750e-01\n",
      "  5.12250e-01  1.82750e-01 -9.95750e-01  5.03000e-01  7.62500e-02\n",
      "  1.16750e-01  6.86750e-01 -1.08000e-01 -4.75000e-02  2.65000e-01\n",
      " -5.50750e-01 -1.21250e-01  3.90750e-01 -9.56000e-01 -9.91000e-01\n",
      " -2.45750e-01  1.52750e-01  5.96000e-01  8.17500e-02  3.81750e-01\n",
      " -1.81250e-01 -5.26500e-01  7.94750e-01 -2.05000e-01  9.75750e-01\n",
      "  9.19500e-01  1.11250e-01  4.12250e-01 -2.15150e+00 -8.97750e-01\n",
      "  7.19000e-01  6.81000e-01  1.09525e+00 -1.12500e-01  2.08750e-01\n",
      " -1.17500e-01 -6.31000e-01  7.61750e-01 -7.47750e-01  4.60750e-01\n",
      " -3.16500e-01  4.80000e-02  1.33125e+00  6.50250e-01  2.72000e-01\n",
      "  2.76000e-01  6.26000e-01 -1.39100e+00 -6.82500e-02  2.63500e-01\n",
      " -2.36250e-01 -1.17125e+00  1.00375e+00  7.67000e-01 -3.33000e-01\n",
      " -5.35000e-01 -3.78750e-01 -2.22000e-01  8.16250e-01  4.49000e-01\n",
      "  5.88500e-01 -7.98500e-01  5.33000e-01  6.28500e-01 -1.29600e+00\n",
      "  1.21500e+00  1.53000e-01  1.24500e-01  6.43250e-01 -1.07800e+00\n",
      "  5.52250e-01  1.77450e+00  9.79750e-01 -1.78000e+00  2.19850e+00\n",
      " -1.77000e-01 -4.70250e-01 -7.81500e-01 -7.93000e-01  7.10000e-01\n",
      "  2.93750e-01 -6.71000e-01 -3.44500e-01  8.89000e-01  5.31000e-01\n",
      " -4.02500e-02  3.02500e-02 -5.04250e-01  3.77000e-01 -4.61500e-01\n",
      " -2.10250e-01 -1.15475e+00  4.72500e-01  3.62500e-02 -1.38300e+00\n",
      "  1.68225e+00  6.77500e-02 -5.26500e-01 -7.51500e-01 -9.27750e-01\n",
      " -1.39300e+00 -4.26250e-01 -1.11250e-01  7.23000e-01 -5.21750e-01\n",
      " -8.31250e-01 -5.05000e-01 -9.67500e-01  2.15500e-01  1.01250e+00\n",
      " -5.25000e-01  6.78750e-01  5.07000e-01  2.65000e-01  3.62500e-01\n",
      "  1.40750e-01 -1.25425e+00  9.97500e-01 -4.24750e-01  5.67500e-02\n",
      "  1.44775e+00  1.67500e-01 -4.24250e-01 -4.91000e-01  6.37500e-01\n",
      "  1.56750e-01  2.74000e-01]\n",
      "  H_L4 Detail:\n",
      "[ 1.862000e+00 -1.575625e+00 -3.061250e-01  5.083750e-01 -2.620000e+00\n",
      "  1.272750e+00 -2.331250e-01 -3.793750e-01  8.327500e-01 -1.124625e+00\n",
      " -2.766250e-01  1.321500e+00 -5.092500e-01 -1.506500e+00 -5.368750e-01\n",
      "  3.110000e-01  7.778750e-01  5.877500e-01  1.475000e-01  1.017875e+00\n",
      "  3.501625e+00 -1.922500e+00  1.206250e+00  1.823875e+00  2.456625e+00\n",
      " -5.272875e+00  2.001625e+00 -1.880750e+00  1.539750e+00 -2.157500e-01\n",
      " -1.106000e+00  4.312500e-02 -1.044625e+00 -8.930000e-01 -4.621250e-01\n",
      "  3.142500e-01 -4.656250e-01  9.565000e-01  6.993750e-01 -1.315000e-01\n",
      " -1.110125e+00 -6.252500e-01  9.537500e-02  1.677625e+00  2.285000e-01\n",
      "  9.972500e-01  1.016250e-01  3.081500e+00  5.458750e-01 -1.788625e+00\n",
      "  1.790750e+00  6.592500e-01 -8.105000e-01  2.385125e+00 -4.854750e+00\n",
      "  6.614625e+00 -2.755375e+00 -1.726125e+00 -2.090000e+00 -3.373625e+00\n",
      " -5.627500e-01 -6.713750e-01 -6.825000e-02 -4.817500e-01 -8.143750e-01\n",
      "  1.453375e+00  2.695000e-01  6.878750e-01 -5.006250e-01 -2.106250e+00\n",
      " -1.181125e+00 -2.248500e+00 -6.461250e-01  4.241250e-01 -1.375000e-02\n",
      " -2.140000e-01  1.008125e+00  5.811250e-01  1.828750e-01  3.353500e+00\n",
      "  1.591000e+00 -4.284625e+00 -2.257375e+00 -5.022500e-01  2.699500e+00\n",
      " -1.069500e+00 -6.147500e-01 -2.390375e+00  9.545000e-01  1.209000e+00\n",
      "  1.070250e+00  8.543750e-01 -3.113750e-01 -1.459375e+00 -3.832250e+00\n",
      " -2.808750e-01 -1.193750e-01 -1.007875e+00 -7.387500e-02 -5.570000e-01\n",
      "  5.162500e-02  1.314375e+00  3.592625e+00 -1.781250e+00 -1.380625e+00\n",
      " -7.140000e-01  4.678750e-01  1.142250e+00 -2.418250e+00  7.990000e-01\n",
      "  3.990000e-01 -4.323750e-01 -2.865000e-01  5.975000e-01 -1.276500e+00\n",
      " -4.832500e-01 -8.971250e-01  5.571250e-01  1.565875e+00 -1.182500e-01\n",
      " -5.912500e-01  7.550000e-02 -3.347500e-01  4.191250e-01 -8.158750e-01\n",
      "  1.672500e-01  3.800000e-01 -4.380000e-01  8.462500e-02  7.496250e-01\n",
      "  9.428750e-01  1.231500e+00 -3.750000e-03  1.426375e+00  1.645500e+00\n",
      "  6.678750e-01 -3.240000e-01 -1.021500e+00  4.865000e-01 -1.465125e+00\n",
      " -6.397500e-01 -7.562500e-02 -1.001875e+00 -1.985000e-01 -9.258750e-01\n",
      " -6.237500e-02  7.903750e-01 -2.162500e-01  1.692375e+00 -7.138750e-01\n",
      "  1.194125e+00 -1.230250e+00  2.694375e+00  1.216625e+00  1.286250e-01\n",
      " -1.374750e+00 -3.312500e-01 -8.388750e-01 -7.271250e-01  1.580000e-01\n",
      " -2.329500e+00 -8.005000e-01  1.504750e+00 -2.538000e+00 -1.279750e+00\n",
      " -8.916250e-01  1.812375e+00  3.770000e-01  5.275000e-02 -7.425000e-01\n",
      " -9.272500e-01  5.167875e+00 -1.020750e+00 -3.468750e-01 -7.416250e-01\n",
      " -1.394875e+00  2.320000e+00  2.125000e+00 -1.476500e+00  2.062000e+00\n",
      "  2.254125e+00 -5.071250e-01 -1.047125e+00 -2.947500e-01 -1.282875e+00\n",
      "  1.179750e+00  6.176250e-01  6.591250e-01  1.237500e-02 -1.546625e+00\n",
      "  9.778750e-01  1.141250e+00 -2.601625e+00 -1.554250e+00  2.281000e+00\n",
      " -4.710000e-01 -1.844750e+00 -5.700000e-02 -8.457500e-01  1.050125e+00\n",
      "  1.592500e-01 -3.790000e-01 -6.336250e-01  3.262500e-01 -2.317250e+00\n",
      " -3.812500e-01  5.018750e-01  1.098250e+00  7.762500e-02  5.336250e-01\n",
      "  8.581250e-01 -2.221875e+00 -4.868750e-01  1.797125e+00  4.208750e-01\n",
      " -5.065000e-01  8.705000e-01  1.606250e-01  1.226875e+00  4.008750e-01\n",
      "  8.022500e-01 -1.569125e+00 -4.361250e-01 -7.025000e-02  4.097500e-01\n",
      " -1.146625e+00  6.198750e-01  6.202500e-01 -6.307500e-01 -1.114000e+00\n",
      "  2.148750e+00  1.250875e+00 -8.876250e-01  2.638125e+00 -2.005000e-01\n",
      " -1.396875e+00 -8.435000e-01  1.026375e+00 -1.169500e+00  1.714750e+00\n",
      "  7.337500e-01 -6.381250e-01 -6.013750e-01 -8.061250e-01 -2.753125e+00\n",
      "  1.361000e+00 -7.960000e-01 -2.589875e+00 -4.487500e-01  6.161250e-01\n",
      " -1.449625e+00 -7.265000e-01 -4.120000e-01  1.275125e+00 -1.010000e-01\n",
      " -1.512500e+00  5.503750e-01  1.487000e+00  8.312500e-02  5.005000e-01\n",
      "  5.253750e-01]\n",
      "------------------------------\n",
      "Saved all Haar LWT coefficients (in columns) to: ./haar_lwt_1D_L4_coeffs_speed_dataset.csv\n",
      "Saved coefficients to directory: .//haar_lwt_1D_L4_coeffs_speed_dataset.csv\n",
      "------------------------------\n",
      "\n",
      "--- Reconstruction Results ---\n",
      "Reconstructed Data: [7.343 8.013 8.293 ... 9.517 9.46  9.309]\n",
      "Is Reconstruction Accurate? True\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def haar_lwt_1d_decompose(data):\n",
    "    \"\"\"\n",
    "    Performs a single level 1D Haar Lifting Wavelet Transform decomposition.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): The 1D input data array.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - approximation (np.ndarray): The approximation coefficients.\n",
    "            - detail (np.ndarray): The detail coefficients.\n",
    "            - original_len (int): The original length of the input data before padding.\n",
    "    \"\"\"\n",
    "    original_len = len(data)\n",
    "    \n",
    "    # Pad if length is odd to ensure even split\n",
    "    if original_len % 2 != 0:\n",
    "        padded_data = np.pad(data, (0, 1), 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data = data\n",
    "\n",
    "    # Split: Separate into even and odd indexed samples\n",
    "    even = padded_data[::2]\n",
    "    odd = padded_data[1::2]\n",
    "\n",
    "    # Predict: Calculate detail coefficients (d_j = odd - even)\n",
    "    detail = odd - even\n",
    "\n",
    "    # Update: Calculate approximation coefficients (s_j = even + d_j / 2)\n",
    "    approximation = even + detail / 2\n",
    "\n",
    "    return approximation, detail, original_len\n",
    "\n",
    "def haar_lwt_1d_reconstruct(approximation, detail, original_len):\n",
    "    \"\"\"\n",
    "    Reconstructs a 1D signal from its single level Haar Lifting Wavelet Transform coefficients.\n",
    "\n",
    "    Args:\n",
    "        approximation (np.ndarray): The approximation coefficients.\n",
    "        detail (np.ndarray): The detail coefficients.\n",
    "        original_len (int): The original length of the signal before decomposition padding.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The reconstructed 1D signal.\n",
    "    \"\"\"\n",
    "    # Inverse Update\n",
    "    even = approximation - detail / 2\n",
    "\n",
    "    # Inverse Predict\n",
    "    odd = detail + even\n",
    "\n",
    "    # Merge: Interleave even and odd parts\n",
    "    combined_padded_len = len(even) + len(odd)\n",
    "    reconstructed = np.empty(combined_padded_len, dtype=float)\n",
    "    reconstructed[::2] = even\n",
    "    reconstructed[1::2] = odd\n",
    "    \n",
    "    # Trim to original length\n",
    "    return reconstructed[:original_len]\n",
    "\n",
    "def _apply_1d_lwt_along_axis(data_nd, axis):\n",
    "    \"\"\"\n",
    "    Applies 1D Haar LWT decomposition along a specified axis of an N-dimensional array.\n",
    "\n",
    "    Args:\n",
    "        data_nd (np.ndarray): The N-dimensional input data array.\n",
    "        axis (int): The axis along which to apply the 1D transform.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - approx_coeffs_nd (np.ndarray): N-dimensional approximation coefficients.\n",
    "            - detail_coeffs_nd (np.ndarray): N-dimensional detail coefficients.\n",
    "            - original_len_axis (int): The original length of the specified axis before padding.\n",
    "    \"\"\"\n",
    "    original_shape = data_nd.shape\n",
    "    original_len_axis = original_shape[axis]\n",
    "\n",
    "    # Handle padding for N-D: If original_shape[axis] is odd, pad along that axis.\n",
    "    pad_width = [(0, 0)] * data_nd.ndim\n",
    "    if original_len_axis % 2 != 0:\n",
    "        pad_width[axis] = (0, 1)\n",
    "        padded_data_nd = np.pad(data_nd, pad_width, 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data_nd = data_nd\n",
    "\n",
    "    # Get even and odd slices along the specified axis\n",
    "    slicer_even = [slice(None)] * padded_data_nd.ndim\n",
    "    slicer_even[axis] = np.arange(0, padded_data_nd.shape[axis], 2)\n",
    "    even_part = padded_data_nd[tuple(slicer_even)]\n",
    "\n",
    "    slicer_odd = [slice(None)] * padded_data_nd.ndim\n",
    "    slicer_odd[axis] = np.arange(1, padded_data_nd.shape[axis], 2)\n",
    "    odd_part = padded_data_nd[tuple(slicer_odd)]\n",
    "\n",
    "    # Predict: detail = odd - even\n",
    "    detail_coeffs_nd = odd_part - even_part\n",
    "\n",
    "    # Update: approximation = even + detail / 2\n",
    "    approx_coeffs_nd = even_part + detail_coeffs_nd / 2\n",
    "\n",
    "    return approx_coeffs_nd, detail_coeffs_nd, original_len_axis\n",
    "\n",
    "def _apply_1d_inverse_lwt_along_axis(approx_coeffs_nd, detail_coeffs_nd, axis, original_len_axis):\n",
    "    \"\"\"\n",
    "    Applies 1D Haar LWT reconstruction along a specified axis of N-dimensional approximation and detail coefficients.\n",
    "\n",
    "    Args:\n",
    "        approx_coeffs_nd (np.ndarray): N-dimensional approximation coefficients.\n",
    "        detail_coeffs_nd (np.ndarray): N-dimensional detail coefficients.\n",
    "        axis (int): The axis along which to apply the 1D inverse transform.\n",
    "        original_len_axis (int): The original length of the axis before decomposition padding.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The reconstructed N-dimensional array.\n",
    "    \"\"\"\n",
    "    # Inverse Update: even = approx - detail / 2\n",
    "    even_part = approx_coeffs_nd - detail_coeffs_nd / 2\n",
    "\n",
    "    # Inverse Predict: odd = detail + even\n",
    "    odd_part = detail_coeffs_nd + even_part\n",
    "\n",
    "    # Merge: Interleave even and odd parts\n",
    "    # Determine the shape of the reconstructed array before trimming\n",
    "    reconstructed_shape = list(even_part.shape)\n",
    "    reconstructed_shape[axis] = even_part.shape[axis] + odd_part.shape[axis]\n",
    "    reconstructed_padded_nd = np.empty(reconstructed_shape, dtype=float)\n",
    "\n",
    "    # Place even parts at even indices and odd parts at odd indices along the axis\n",
    "    slicer_even_out = [slice(None)] * reconstructed_padded_nd.ndim\n",
    "    slicer_even_out[axis] = np.arange(0, reconstructed_padded_nd.shape[axis], 2)\n",
    "    reconstructed_padded_nd[tuple(slicer_even_out)] = even_part\n",
    "\n",
    "    slicer_odd_out = [slice(None)] * reconstructed_padded_nd.ndim\n",
    "    slicer_odd_out[axis] = np.arange(1, reconstructed_padded_nd.shape[axis], 2)\n",
    "    reconstructed_padded_nd[tuple(slicer_odd_out)] = odd_part\n",
    "\n",
    "    # Trim to the original length along the specified axis\n",
    "    trim_slicer = [slice(None)] * reconstructed_padded_nd.ndim\n",
    "    trim_slicer[axis] = slice(0, original_len_axis)\n",
    "    \n",
    "    return reconstructed_padded_nd[tuple(trim_slicer)]\n",
    "\n",
    "def haar_lwt_nd_decompose(data, level):\n",
    "    \"\"\"\n",
    "    Performs an N-level N-dimensional Haar Lifting Wavelet Transform decomposition.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): The N-dimensional input data array.\n",
    "        level (int): The number of decomposition levels to perform.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "              - 'original_shape': tuple, original shape of the input data.\n",
    "              - 'final_approx': np.ndarray, the final approximation sub-band (all Ls).\n",
    "              - 'level_X_details': dict, where X is the level number.\n",
    "                - Keys are sub-band names (e.g., 'LH', 'HL', 'HH' for 2D, or 'LLH', 'LHL', etc. for 3D).\n",
    "                  The name is a string of 'L' and 'H' characters, where 'L' means low-pass\n",
    "                  and 'H' means high-pass along the corresponding dimension. The order of characters\n",
    "                  corresponds to the order of dimensions (axis 0, axis 1, ...).\n",
    "                - Values are np.ndarray, the coefficient arrays for that sub-band.\n",
    "              - 'level_X_input_shapes_before_axis_transform': dict.\n",
    "                - Keys are the prefixes (L/H combinations) of the sub-bands *before* a 1D transform\n",
    "                  was applied along a specific axis.\n",
    "                - Values are the full N-dimensional shape of that sub-band *before* the 1D transform.\n",
    "                  This is crucial for reconstruction.\n",
    "    \"\"\"\n",
    "    current_approx = np.array(data, dtype=float)\n",
    "    coeffs_tree = {'original_shape': data.shape}\n",
    "    \n",
    "    ndim = data.ndim\n",
    "\n",
    "    for l in range(1, level + 1):\n",
    "        details_this_level = {}\n",
    "        # Stores the shape of the array that was input to the 1D transform along each axis.\n",
    "        # Key: The L/H prefix of the sub-band *before* the current axis was processed.\n",
    "        # Value: The shape of that sub-band.\n",
    "        level_l_input_shapes_before_axis_transform = {}\n",
    "\n",
    "        current_set_of_arrays = {'': current_approx} # Start with empty prefix for the initial array\n",
    "        \n",
    "        # Iterate through each dimension (axis)\n",
    "        for dim_idx in range(ndim):\n",
    "            next_set_of_arrays = {}\n",
    "            \n",
    "            # Iterate through the arrays accumulated from previous dimension transforms\n",
    "            for input_prefix, arr_to_process in current_set_of_arrays.items():\n",
    "                if arr_to_process.size == 0: # Skip empty arrays if they resulted from previous padding\n",
    "                    continue\n",
    "\n",
    "                # Store the shape of the array *before* applying 1D LWT along this dim_idx\n",
    "                # The key here is the prefix *leading up to* this dimension.\n",
    "                # This shape is needed for reconstruction.\n",
    "                level_l_input_shapes_before_axis_transform[input_prefix] = arr_to_process.shape\n",
    "\n",
    "                # Apply 1D LWT along the current dimension\n",
    "                approx_part, detail_part, _ = _apply_1d_lwt_along_axis(arr_to_process, dim_idx) # _ is original_len_axis\n",
    "                \n",
    "                # Store the approximation and detail parts with updated prefixes\n",
    "                next_set_of_arrays[input_prefix + 'L'] = approx_part\n",
    "                next_set_of_arrays[input_prefix + 'H'] = detail_part\n",
    "            \n",
    "            # Update the set of arrays for the next dimension's processing\n",
    "            current_set_of_arrays = next_set_of_arrays\n",
    "        \n",
    "        # After processing all dimensions for this level, `current_set_of_arrays`\n",
    "        # contains all 2^ndim sub-bands.\n",
    "        # The 'L'*ndim key holds the approximation for the next level.\n",
    "        current_approx = current_set_of_arrays.pop('L' * ndim)\n",
    "        \n",
    "        # The remaining items in `current_set_of_arrays` are the detail sub-bands for this level.\n",
    "        details_this_level = current_set_of_arrays\n",
    "\n",
    "        coeffs_tree[f'level_{l}_details'] = details_this_level\n",
    "        coeffs_tree[f'level_{l}_input_shapes_before_axis_transform'] = level_l_input_shapes_before_axis_transform\n",
    "        \n",
    "        # Check if the approximation sub-band is too small for further decomposition\n",
    "        if any(s < 2 for s in current_approx.shape) or current_approx.size == 0:\n",
    "            print(f\"Warning: Stopped N-D decomposition at level {l} because approximation sub-band became too small: {current_approx.shape}\")\n",
    "            break\n",
    "    \n",
    "    coeffs_tree['final_approx'] = current_approx\n",
    "    return coeffs_tree\n",
    "\n",
    "def haar_lwt_nd_reconstruct(coeffs_tree):\n",
    "    \"\"\"\n",
    "    Reconstructs an N-dimensional signal from its N-level Haar Lifting Wavelet Transform coefficients.\n",
    "\n",
    "    Args:\n",
    "        coeffs_tree (dict): A dictionary containing the final approximation sub-band\n",
    "                            and all detail sub-bands (LH, HL, HH, etc.) for each level,\n",
    "                            as returned by `haar_lwt_nd_decompose`.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The reconstructed N-dimensional signal.\n",
    "    \"\"\"\n",
    "    current_reconstruction = coeffs_tree['final_approx']\n",
    "    original_full_shape = coeffs_tree['original_shape']\n",
    "    ndim = len(original_full_shape)\n",
    "\n",
    "    # Determine the number of levels from the keys in coeffs_tree\n",
    "    levels = 0\n",
    "    for key in coeffs_tree:\n",
    "        if key.startswith('level_') and key.endswith('_details'):\n",
    "            levels = max(levels, int(key.split('_')[1]))\n",
    "    \n",
    "    # Reconstruct level by level, from coarsest to finest\n",
    "    for l in range(levels, 0, -1):\n",
    "        details_this_level = coeffs_tree[f'level_{l}_details']\n",
    "        input_shapes_before_axis_transform = coeffs_tree[f'level_{l}_input_shapes_before_axis_transform']\n",
    "\n",
    "        # Start with all 2^ndim sub-bands for this level, including the current_reconstruction (LL...L)\n",
    "        all_sub_bands_at_this_level = details_this_level.copy()\n",
    "        all_sub_bands_at_this_level['L' * ndim] = current_reconstruction\n",
    "\n",
    "        # Iterate through dimensions in reverse order for reconstruction\n",
    "        for dim_idx in range(ndim - 1, -1, -1):\n",
    "            next_reconstructed_arrays = {}\n",
    "            \n",
    "            # Generate all possible prefixes for the dimensions *before* dim_idx (L/H combinations)\n",
    "            prefix_combinations = [''.join(p) for p in product('LH', repeat=dim_idx)]\n",
    "            # Suffixes for dimensions *after* dim_idx, which have already been reconstructed ('R' combinations)\n",
    "            reconstruct_suffix_combinations = [''.join(p) for p in product('R', repeat=(ndim - 1 - dim_idx))]\n",
    "\n",
    "            for p_before in prefix_combinations:\n",
    "                for r_suffix in reconstruct_suffix_combinations:\n",
    "                    approx_key = p_before + 'L' + r_suffix\n",
    "                    detail_key = p_before + 'H' + r_suffix\n",
    "                    \n",
    "                    if approx_key in all_sub_bands_at_this_level and detail_key in all_sub_bands_at_this_level:\n",
    "                        approx_part = all_sub_bands_at_this_level[approx_key]\n",
    "                        detail_part = all_sub_bands_at_this_level[detail_key]\n",
    "                        \n",
    "                        # The prefix used when this `dim_idx` was processed in the forward pass\n",
    "                        # is simply `p_before`.\n",
    "                        input_prefix_for_lookup = p_before\n",
    "                        \n",
    "                        original_input_shape_for_this_dim = input_shapes_before_axis_transform.get(input_prefix_for_lookup)\n",
    "\n",
    "                        if original_input_shape_for_this_dim is None:\n",
    "                            raise KeyError(f\"Original input shape not found for (dim_idx={dim_idx}, input_prefix='{input_prefix_for_lookup}') at level {l}. \"\n",
    "                                           f\"Approx key: '{approx_key}', Detail key: '{detail_key}'\")\n",
    "\n",
    "                        original_len_for_this_axis = original_input_shape_for_this_dim[dim_idx]\n",
    "\n",
    "                        reconstructed_part = _apply_1d_inverse_lwt_along_axis(\n",
    "                            approx_part, detail_part, dim_idx, original_len_for_this_axis\n",
    "                        )\n",
    "                        \n",
    "                        # The key for the next level of reconstruction is `p_before + 'R' + r_suffix`\n",
    "                        # This key needs to be consistent for the next iteration of dim_idx.\n",
    "                        # The 'R' for the current dim_idx is added here.\n",
    "                        next_reconstructed_arrays[p_before + 'R' + r_suffix] = reconstructed_part\n",
    "            \n",
    "            # CRITICAL FIX: Update all_sub_bands_at_this_level for the next dimension's processing\n",
    "            all_sub_bands_at_this_level = next_reconstructed_arrays\n",
    "        \n",
    "        # After all dimensions are reconstructed for this level, there should be only one array left\n",
    "        # which is the full approximation for the previous level.\n",
    "        current_reconstruction = all_sub_bands_at_this_level['R' * ndim]\n",
    "    \n",
    "    # Final trim to the original input data shape\n",
    "    final_reconstruction_slicer = tuple(slice(0, s) for s in original_full_shape)\n",
    "    return current_reconstruction[final_reconstruction_slicer]\n",
    "\n",
    "\n",
    "def save_coefficients_to_files(output_dir, coeffs_tree, filename='all_haar_lwt_coeffs_columns_nd.csv'):\n",
    "    \"\"\"\n",
    "    Saves all Haar LWT coefficients (approximation and all detail levels) into a single .csv file,\n",
    "    with each coefficient type in its own column. Handles N-dimensional data.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): The directory where the coefficient file will be saved.\n",
    "                          If the directory does not exist, it will be created.\n",
    "        coeffs_tree (dict): A dictionary containing the final approximation sub-band\n",
    "                            and all detail sub-bands for each level,\n",
    "                            as returned by `haar_lwt_nd_decompose`.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    all_coeff_arrays_flat = []\n",
    "    headers = []\n",
    "\n",
    "    # Add the final approximation (LL...L)\n",
    "    if 'final_approx' in coeffs_tree:\n",
    "        all_coeff_arrays_flat.append(coeffs_tree['final_approx'].flatten())\n",
    "        headers.append('Final_Approximation')\n",
    "\n",
    "    # Determine the number of levels and dimensions\n",
    "    levels = 0\n",
    "    ndim = len(coeffs_tree['original_shape'])\n",
    "    for key in coeffs_tree:\n",
    "        if key.startswith('level_') and key.endswith('_details'):\n",
    "            levels = max(levels, int(key.split('_')[1]))\n",
    "\n",
    "    # Generate all possible L/H combinations for N dimensions\n",
    "    all_lh_combinations = [''.join(p) for p in product('LH', repeat=ndim)]\n",
    "    \n",
    "    # Exclude the 'L'*ndim combination as it's the approximation for the next level\n",
    "    # or the final_approx.\n",
    "    detail_lh_combinations = [c for c in all_lh_combinations if c != 'L' * ndim]\n",
    "\n",
    "    # Add detail coefficients for each level\n",
    "    for l in range(1, levels + 1):\n",
    "        details_this_level = coeffs_tree.get(f'level_{l}_details', {})\n",
    "        # Sort detail combinations for consistent column order in CSV\n",
    "        for combo in sorted(detail_lh_combinations):\n",
    "            if combo in details_this_level and details_this_level[combo].size > 0:\n",
    "                all_coeff_arrays_flat.append(details_this_level[combo].flatten())\n",
    "                headers.append(f'{combo}_L{l}')\n",
    "\n",
    "    # Find the maximum length among all flattened coefficient arrays\n",
    "    max_len = 0\n",
    "    if all_coeff_arrays_flat:\n",
    "        max_len = max(len(arr) for arr in all_coeff_arrays_flat)\n",
    "\n",
    "    # Pad shorter arrays with NaN\n",
    "    padded_coeff_arrays = []\n",
    "    for arr in all_coeff_arrays_flat:\n",
    "        if len(arr) < max_len:\n",
    "            padded_arr = np.pad(arr, (0, max_len - len(arr)), 'constant', constant_values=np.nan)\n",
    "        else:\n",
    "            padded_arr = arr\n",
    "        padded_coeff_arrays.append(padded_arr)\n",
    "\n",
    "    # Stack the padded arrays horizontally\n",
    "    if padded_coeff_arrays:\n",
    "        combined_coeffs_2d = np.column_stack(padded_coeff_arrays)\n",
    "    else:\n",
    "        combined_coeffs_2d = np.array([[]])\n",
    "\n",
    "    header_str = ','.join(headers)\n",
    "\n",
    "    combined_filepath = os.path.join(output_dir, filename)\n",
    "    np.savetxt(combined_filepath, combined_coeffs_2d, delimiter=',', header=header_str, comments='')\n",
    "    print(f\"Saved all Haar LWT coefficients (in columns) to: {combined_filepath}\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df = pd.read_csv('Data_August_Renewable.csv')\n",
    "    data = df['Speed'].values\n",
    "    n_levels = 4\n",
    "    print(f\"Original Data: {data}\")\n",
    "    print(f\"Decomposition Levels: {n_levels}\")\n",
    "    print(\"-\" * 30) \n",
    "    coeffs = haar_lwt_nd_decompose(data, n_levels)\n",
    "    print(\"\\n--- Decomposition Results ---\")\n",
    "    print(f\"Final LL (Approximation) Sub-band:\\n{coeffs['final_approx']}\")\n",
    "    for l in range(1, n_levels + 1):\n",
    "        details = coeffs.get(f'level_{l}_details', {})\n",
    "        for key, val in details.items():\n",
    "            print(f\"  {key}_L{l} Detail:\\n{val}\")\n",
    "    print(\"-\" * 30)\n",
    "    output_directory = './'\n",
    "    save_coefficients_to_files(output_directory, coeffs, filename=f'haar_lwt_1D_L{n_levels}_coeffs_speed_dataset.csv')\n",
    "    print(f\"Saved coefficients to directory: {output_directory}/haar_lwt_1D_L{n_levels}_coeffs_speed_dataset.csv\")\n",
    "    print(\"-\" * 30)\n",
    "    reconstructed_data = haar_lwt_nd_reconstruct(coeffs)\n",
    "    print(\"\\n--- Reconstruction Results ---\")\n",
    "    print(f\"Reconstructed Data: {reconstructed_data}\")\n",
    "    is_reconstruction_accurate = np.allclose(data, reconstructed_data)\n",
    "    print(f\"Is Reconstruction Accurate? {is_reconstruction_accurate}\")\n",
    "    if not is_reconstruction_accurate:\n",
    "        print(f\"Difference: {data - reconstructed_data}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # # --- 1D Example (still works with the new N-D functions) ---\n",
    "    # print(\"--- 1D Example ---\")\n",
    "    # data_1d = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "    # n_levels_1d = 2\n",
    "\n",
    "    # print(f\"Original 1D Data: {data_1d}\")\n",
    "    # print(f\"Decomposition Levels: {n_levels_1d}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # coeffs_1d = haar_lwt_nd_decompose(data_1d, n_levels_1d)\n",
    "    # print(\"\\n--- 1D Decomposition Results ---\")\n",
    "    # print(f\"Final LL (Approximation) Sub-band:\\n{coeffs_1d['final_approx']}\")\n",
    "    # for l in range(1, n_levels_1d + 1):\n",
    "    #     details = coeffs_1d.get(f'level_{l}_details', {})\n",
    "    #     for key, val in details.items():\n",
    "    #         print(f\"  {key}_L{l} Detail:\\n{val}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # output_directory_1d = 'haar_lwt_coeffs_1d'\n",
    "    # save_coefficients_to_files(output_directory_1d, coeffs_1d)\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # reconstructed_data_1d = haar_lwt_nd_reconstruct(coeffs_1d)\n",
    "    # print(\"\\n--- 1D Reconstruction Results ---\")\n",
    "    # print(f\"Reconstructed Data: {reconstructed_data_1d}\")\n",
    "    # is_reconstruction_accurate_1d = np.allclose(data_1d, reconstructed_data_1d)\n",
    "    # print(f\"Is 1D Reconstruction Accurate? {is_reconstruction_accurate_1d}\")\n",
    "    # if not is_reconstruction_accurate_1d:\n",
    "    #     print(f\"Difference: {data_1d - reconstructed_data_1d}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "\n",
    "    # # --- 2D Example ---\n",
    "    # print(\"\\n--- 2D Example ---\")\n",
    "    # data_2d = np.array([\n",
    "    #     [1, 2, 3, 4, 5],\n",
    "    #     [6, 7, 8, 9, 10],\n",
    "    #     [11, 12, 13, 14, 15],\n",
    "    #     [16, 17, 18, 19, 20],\n",
    "    #     [21, 22, 23, 24, 25]\n",
    "    # ])\n",
    "    # n_levels_2d = 2\n",
    "\n",
    "    # print(f\"Original 2D Data:\\n{data_2d}\")\n",
    "    # print(f\"Original 2D Data Shape: {data_2d.shape}\")\n",
    "    # print(f\"Decomposition Levels: {n_levels_2d}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # coeffs_2d = haar_lwt_nd_decompose(data_2d, n_levels_2d)\n",
    "\n",
    "    # print(\"\\n--- 2D Decomposition Results ---\")\n",
    "    # print(f\"Final LL (Approximation) Sub-band:\\n{coeffs_2d['final_approx']}\")\n",
    "    # for l in range(1, n_levels_2d + 1):\n",
    "    #     details = coeffs_2d.get(f'level_{l}_details', {})\n",
    "    #     # Sort keys for predictable output\n",
    "    #     for key in sorted(details.keys()):\n",
    "    #         val = details[key]\n",
    "    #         print(f\"  {key}_L{l} Detail:\\n{val}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # output_directory_2d = 'haar_lwt_coeffs_2d'\n",
    "    # save_coefficients_to_files(output_directory_2d, coeffs_2d)\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # reconstructed_data_2d = haar_lwt_nd_reconstruct(coeffs_2d)\n",
    "\n",
    "    # print(\"\\n--- 2D Reconstruction Results ---\")\n",
    "    # print(f\"Reconstructed Data:\\n{reconstructed_data_2d}\")\n",
    "    # is_reconstruction_accurate_2d = np.allclose(data_2d, reconstructed_data_2d)\n",
    "    # print(f\"Is 2D Reconstruction Accurate? {is_reconstruction_accurate_2d}\")\n",
    "    # if not is_reconstruction_accurate_2d:\n",
    "    #     print(f\"Difference:\\n{data_2d - reconstructed_data_2d}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # # --- 3D Example ---\n",
    "    # print(\"\\n--- 3D Example ---\")\n",
    "    # data_3d = np.arange(1, 28).reshape((3, 3, 3)) # A 3x3x3 array\n",
    "    # n_levels_3d = 1 # For 3x3x3, only 1 level is practical as dimensions become 2x2x2 after 1 level\n",
    "\n",
    "    # print(f\"Original 3D Data:\\n{data_3d}\")\n",
    "    # print(f\"Original 3D Data Shape: {data_3d.shape}\")\n",
    "    # print(f\"Decomposition Levels: {n_levels_3d}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # coeffs_3d = haar_lwt_nd_decompose(data_3d, n_levels_3d)\n",
    "\n",
    "    # print(\"\\n--- 3D Decomposition Results ---\")\n",
    "    # print(f\"Final LLL (Approximation) Sub-band:\\n{coeffs_3d['final_approx']}\")\n",
    "    # for l in range(1, n_levels_3d + 1):\n",
    "    #     details = coeffs_3d.get(f'level_{l}_details', {})\n",
    "    #     # Sort keys for predictable output\n",
    "    #     for key in sorted(details.keys()):\n",
    "    #         val = details[key]\n",
    "    #         print(f\"  {key}_L{l} Detail:\\n{val}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # output_directory_3d = 'haar_lwt_coeffs_3d'\n",
    "    # save_coefficients_to_files(output_directory_3d, coeffs_3d)\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # reconstructed_data_3d = haar_lwt_nd_reconstruct(coeffs_3d)\n",
    "\n",
    "    # print(\"\\n--- 3D Reconstruction Results ---\")\n",
    "    # print(f\"Reconstructed Data:\\n{reconstructed_data_3d}\")\n",
    "    # is_reconstruction_accurate_3d = np.allclose(data_3d, reconstructed_data_3d)\n",
    "    # print(f\"Is 3D Reconstruction Accurate? {is_reconstruction_accurate_3d}\")\n",
    "    # if not is_reconstruction_accurate_3d:\n",
    "    #     print(f\"Difference:\\n{data_3d - reconstructed_data_3d}\")\n",
    "    # print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_DL (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
