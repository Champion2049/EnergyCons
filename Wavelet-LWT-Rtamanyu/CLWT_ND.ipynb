{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71fd15aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from itertools import product # Used for generating 'L'/'H' combinations for N-D sub-bands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5a559b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data: [7.343 8.013 8.293 ... 9.517 9.46  9.309]\n",
      "Decomposition Levels: 3\n",
      "------------------------------\n",
      "\n",
      "--- Decomposition Results ---\n",
      "Final LL (Approximation) Sub-band:\n",
      "[ 8.66025  10.52225  11.473875  9.89825   8.885375  8.57925   8.941375\n",
      "  9.44975   9.751125  7.131125  7.585     8.85775   7.9645    7.731375\n",
      "  7.33875   6.959375  6.54575   7.3785    6.78725   5.662625  5.909375\n",
      "  5.63275   6.86375   8.18525   9.0265    8.51725   8.152     6.6455\n",
      "  5.680625  5.14375   4.86425   5.17525   5.9905    6.768375  7.463125\n",
      "  8.050875  6.94025   7.08775   7.49425   8.512125 11.245875 14.7475\n",
      " 13.5905   11.668    12.974    14.18025  12.924875 14.74875  17.752\n",
      " 20.208625 15.42875  10.155875 10.0735   12.075125 10.194375  8.313625\n",
      " 11.446    12.98575  12.456    12.24025  10.465375  9.359375  9.949375\n",
      "  9.9925    9.357875  8.31325   7.612625  6.719625  6.17175   5.709625\n",
      "  6.491875  6.806125  6.165     5.699375  6.435625  7.392125  7.954625\n",
      "  8.654     8.7615    8.63      8.61975   7.509625  7.145625  6.520375\n",
      "  6.248     6.343375  5.96325   7.640875  8.125375  8.353875  9.2\n",
      " 10.19725  10.143875 10.2455    9.422    12.5035   13.9105   14.456375\n",
      " 15.617125 13.8285   11.55075  13.3415   15.730375 16.389625 17.988\n",
      " 17.1775   18.133    20.518125 18.126375 13.271625  8.617125 15.23175\n",
      " 21.372    18.616625 15.077125 13.351    14.539    12.449    11.876375\n",
      "  8.50275  11.733    11.17025  11.61025  10.938875 11.8505   11.78225\n",
      " 10.9665   10.48475  11.2555   10.441125 11.47925  12.932625 13.06025\n",
      " 13.32975  12.867625 13.5555   13.7155   13.214875 12.766375 10.660125\n",
      "  8.951375  7.77025   6.262625  4.014125  2.785875  2.13975   0.597625\n",
      "  1.02175   1.456125  1.442375  0.9555    0.7415    0.592625  1.60075\n",
      "  1.73175   2.312875  3.714625  3.8975    3.644625  6.998125  7.159\n",
      "  8.75      9.7755    5.490875  7.954875  5.6975    7.338     6.83575\n",
      "  7.3725   10.072     8.8165    7.747     8.083375  7.468625  5.83175\n",
      "  3.441375  1.663     2.6175    6.084375  7.293375  9.357    10.42725\n",
      " 11.783875 12.63825  12.731    12.419625 12.3275   10.868125  9.7605\n",
      "  5.92825   6.054625  5.77375   5.555     5.435625  4.725125  3.71725\n",
      "  3.489375  3.4155    1.332125  0.775125  0.788125  0.83975   2.580125\n",
      "  3.8945    4.302875  7.8955   10.286875  8.505625  6.81775   5.437125\n",
      "  5.715375  5.001375  5.168625  5.6365    6.858875  8.001125  8.6135\n",
      "  6.19525   4.923875  5.722875  5.653625  6.052625  6.41725   5.984875\n",
      "  6.2245    5.938     6.680625  7.278125  6.556625  5.280125  3.702125\n",
      "  3.218875  1.907     1.009875  2.959     3.516125  7.31575   8.881625\n",
      "  8.531625  8.413375  8.195     7.60375   6.89275   6.96825   6.611875\n",
      "  6.277125  6.686125  7.10525   7.404125  6.58825   4.764     4.93125\n",
      "  6.25825   6.63825   6.804125  6.366125  6.304875  6.3895    5.555125\n",
      "  6.30475   9.085875 10.02875   9.5365   10.768    12.1735   12.16975\n",
      " 14.924875 16.35125  15.795625 17.441125 16.6355   17.303375 17.86325\n",
      " 17.53925  17.45525  16.43375  17.3345   17.821    17.229625 15.7645\n",
      " 14.809875 14.170125 14.051    13.975375 13.263625 12.26175  11.558625\n",
      " 11.360125 10.423125  9.49725  11.0045   10.942125  8.9645    9.754875\n",
      " 10.182625  9.966375 10.107    11.799375 12.08975  11.375875  9.510375\n",
      " 10.7045   11.4825   10.25225  12.880625 15.575    17.858125 19.07475\n",
      " 18.4295   18.558125 18.7685   17.39375  16.2755   15.94425  16.62075\n",
      " 15.781875 17.448375 16.72125  17.1875   17.3455   16.897875 14.568375\n",
      " 13.168    12.3675   14.25025  15.755    13.767625 11.229625 10.0075\n",
      "  8.72775   7.077875  6.18625   6.28625   8.098625  9.42225   9.79925\n",
      "  9.368625  9.421375  7.008375  6.265875  1.581875  0.654625  4.31\n",
      "  9.477875  9.156125  8.135375  7.554     7.207125  6.04875   5.307125\n",
      "  6.231875  4.837     4.483125  6.803125  9.562875 11.687875 13.119375\n",
      " 11.642875 10.6815   12.7435   12.954    15.208125 16.38875  15.881625\n",
      " 15.787    14.739875 13.840875 13.546125 13.4865   12.203625 11.720625\n",
      " 12.900375 11.43225  12.049875 13.773625 14.43275  13.680625 13.693\n",
      " 11.832625 10.286    12.02775  13.005625 11.602625 12.743875 10.162375\n",
      "  7.56075   8.786375  7.232125  7.000875  9.281875  9.61025   9.13925\n",
      "  7.186     5.34125   4.315125  4.258125  4.646125  3.800375  3.09075\n",
      "  4.140875  4.299125  4.458375  6.24825   5.86925   6.251     5.617375\n",
      "  4.979375  5.305625  4.99175   2.6745    0.986125  0.604875  1.34525\n",
      "  1.847125  2.162875  3.261125  2.63775   2.715375  3.3255    3.859125\n",
      "  5.82575   6.683875  7.152125  4.93025   3.367625  2.88075   4.00425\n",
      "  5.801375  6.83025   7.251125  7.5675    7.061     6.988875  7.859375\n",
      "  9.494875  9.6555   10.286    11.512875 12.948125 13.349    13.834\n",
      " 14.63625  12.58425  11.015125 11.20125  10.765125  8.887625  8.817375\n",
      " 10.894    11.30375  10.72925   9.582625  8.87175   9.491625 10.39875\n",
      " 11.019    11.06925  10.4385   11.9695   10.8555   10.73425  12.883\n",
      " 13.421    14.671875 15.20325  14.315625 15.8165   18.454625 16.80775\n",
      " 16.60725  21.0665   19.669625 17.49325  16.64975  15.89325  16.919625\n",
      " 17.795    16.6255   17.09825  18.813    18.805875 19.539625 19.577625\n",
      " 18.9395   18.43675  17.835375 16.512125 15.706    16.685875 13.93275\n",
      " 13.039625 14.400625 13.86925  13.07325  11.455875  8.866     8.039875\n",
      "  7.591125  8.353     8.969125  7.814875  6.36525   4.62025   3.89375\n",
      "  5.287     4.875     5.697125  6.97225   7.36225   7.26125   8.055625\n",
      "  6.543125  5.80925   6.359625  5.365375  6.852375  8.68425   8.767375\n",
      "  8.12925   8.62975   8.765875  9.29125 ]\n",
      "  H_L1 Detail:\n",
      "[ 0.67   0.457  0.235 ...  0.106  0.09  -0.151]\n",
      "  H_L2 Detail:\n",
      "[ 0.8435  0.0845  0.647  ...  0.2315  0.1375 -0.0875]\n",
      "  H_L3 Detail:\n",
      "[ 1.12100e+00  1.24450e+00 -3.39750e-01 -9.15500e-01 -1.76250e-01\n",
      "  2.50000e-02  4.81250e-01  2.97500e-01 -3.58750e-01 -1.69125e+00\n",
      "  1.62800e+00 -3.25000e-02 -6.60500e-01  1.17250e-01 -4.00000e-01\n",
      "  2.75000e-03 -4.00500e-01  1.06150e+00 -1.08750e+00 -1.99750e-01\n",
      " -1.39250e-01  2.80000e-01  7.42500e-01  7.86000e-01 -8.25000e-02\n",
      " -2.06500e-01  1.00000e-01 -1.58950e+00  1.35750e-01 -5.03500e-01\n",
      "  3.40500e-01  1.56000e-01  3.02500e-01  1.55250e-01  5.04250e-01\n",
      "  1.87250e-01 -1.07200e+00  3.26500e-01 -6.70000e-02  1.13325e+00\n",
      "  1.72975e+00  1.78450e+00 -8.10000e-01 -1.62400e+00  2.48800e+00\n",
      " -1.02500e-01  4.92500e-02  1.20650e+00  2.90050e+00 -8.41750e-01\n",
      " -6.50000e+00 -1.96775e+00  1.06000e+00  2.50000e-04 -1.35375e+00\n",
      "  7.76250e-01  1.63550e+00 -3.22500e-01 -9.25000e-02 -6.93500e-01\n",
      " -9.10750e-01 -3.41250e-01  2.80750e-01  1.56500e-01 -2.47250e-01\n",
      " -2.16000e-01 -5.65750e-01 -5.82250e-01 -2.09000e-01  1.27500e-02\n",
      "  3.89750e-01 -4.76750e-01 -4.38500e-01  2.26250e-01  6.04750e-01\n",
      "  1.03250e-01  3.82250e-01  4.79500e-01 -3.91000e-01 -7.25000e-02\n",
      " -7.70000e-02 -6.63250e-01  9.02500e-02 -7.67750e-01  1.91000e-01\n",
      " -1.83250e-01  1.11850e+00  6.96250e-01 -4.37500e-02  1.85750e-01\n",
      "  2.16500e-01 -6.00000e-03  6.31750e-01 -4.75000e-02  4.74500e-01\n",
      "  1.63350e+00  1.61500e-01  6.31750e-01  2.43250e-01 -1.43500e+00\n",
      " -6.24150e+00  4.13300e+00 -1.13750e-01  5.72250e-01 -1.00000e-02\n",
      " -2.10500e-01  1.28300e+00  6.52250e-01 -2.42525e+00 -4.06275e+00\n",
      "  4.10750e-01  1.17200e+00  1.66900e+00 -2.41625e+00 -2.07375e+00\n",
      " -5.12000e-01  1.37400e+00 -1.65600e+00 -9.57250e-01  1.38400e+00\n",
      "  7.42500e-01  3.72500e-01 -6.60000e-01  3.57500e-02  1.27000e-01\n",
      " -3.08500e-01 -1.02000e-01  6.00000e-01  1.83000e-01 -1.02525e+00\n",
      "  1.40900e+00 -1.12250e-01  4.14000e-01 -1.15000e-01  2.01250e-01\n",
      "  2.97500e-01  4.50000e-02 -3.66250e-01 -7.27250e-01 -8.56750e-01\n",
      " -5.61250e-01 -8.46000e-01 -9.73250e-01 -1.12675e+00 -1.68250e-01\n",
      " -1.45000e+00 -3.02750e-01  7.18500e-01  4.62500e-02 -1.82250e-01\n",
      " -2.52000e-01 -7.25000e-02 -4.81250e-01  1.38100e+00 -8.91500e-01\n",
      "  1.57225e+00  4.78250e-01 -1.05450e+00  1.27525e+00  1.36275e+00\n",
      "  4.05500e-01  2.11700e+00 -1.05700e+00  1.22525e+00  1.86750e-01\n",
      " -7.89000e-01  1.48500e+00 -8.43000e-01  2.03100e+00 -6.92500e-01\n",
      "  3.85500e-01 -9.95500e-01  2.60250e-01 -3.70250e-01 -1.42450e+00\n",
      " -6.85750e-01 -3.22000e-01  1.39250e+00  1.54625e+00 -5.46750e-01\n",
      "  2.09300e+00  4.32500e-01  2.34750e-01  2.43500e-01 -1.55000e-01\n",
      " -9.82500e-02 -3.77000e-01 -7.37750e-01 -4.62500e-01 -2.82800e+00\n",
      "  4.76250e-01 -7.84500e-01  8.08500e-01 -5.34750e-01  1.57750e-01\n",
      " -8.78000e-01  6.97500e-02  1.21000e-01 -1.80025e+00  3.44750e-01\n",
      "  1.95250e-01  3.06000e-01  1.46625e+00 -3.11000e-01  8.31750e-01\n",
      "  4.22600e+00 -5.93750e-01 -8.94750e-01 -8.20000e-01 -8.02500e-02\n",
      "  1.00250e-01 -4.72500e-02 -3.17250e-01  3.35000e-01  1.03625e+00\n",
      " -4.47250e-01  3.45000e-01 -1.27800e+00  1.37250e-01  4.68250e-01\n",
      "  7.67500e-02  2.27250e-01 -5.00000e-03 -2.86250e-01  5.10000e-01\n",
      " -4.21000e-01  1.97750e-01  2.66250e-01 -6.87750e-01 -4.22250e-01\n",
      " -1.18325e+00 -3.56250e-01 -7.16500e-01 -8.92500e-02  1.21200e+00\n",
      "  6.15750e-01  2.30950e+00  4.37500e-02  3.22750e-01 -3.72750e-01\n",
      " -2.15500e-01 -3.38500e-01 -3.64500e-01  2.23500e-01 -1.59250e-01\n",
      "  1.43425e+00 -1.62475e+00  6.00000e-03  1.65250e-01 -7.59500e-01\n",
      " -1.06200e+00  2.02850e+00 -8.25000e-02  1.13500e+00 -9.41750e-01\n",
      " -9.52500e-02  2.78750e-01 -5.05000e-01 -3.16250e-01  1.06700e+00\n",
      "  1.28225e+00  2.25000e-02  1.98500e-01  7.64000e-01  1.08200e+00\n",
      " -1.57500e+00  1.96825e+00 -2.31000e-01 -5.28750e-01  4.04750e-01\n",
      "  2.47500e-01 -3.14250e-01  6.12500e-01 -2.29000e-01 -4.53500e-01\n",
      "  3.53500e-01  9.01500e-01  5.21500e-01 -6.87250e-01 -8.62500e-01\n",
      " -6.71250e-01 -3.27500e-02  2.10500e-01  9.92500e-02 -7.00250e-01\n",
      " -3.58500e-01 -2.50750e-01  4.27500e-02 -4.58250e-01 -1.22000e-01\n",
      "  5.83000e-01 -1.37775e+00 -5.70500e-01 -1.42500e-02 -7.07500e-02\n",
      "  9.27500e-02  2.53000e-01  1.15675e+00 -3.38000e-01 -8.00750e-01\n",
      " -4.88750e-01  2.13500e-01  8.97000e-01 -2.29000e-01  1.87825e+00\n",
      "  8.37500e-01  8.07250e-01 -1.83500e-01  1.05000e+00  7.29750e-01\n",
      " -3.34000e-01 -1.18700e+00 -8.86500e-01  7.33000e-01  8.90000e-01\n",
      " -1.35975e+00  4.61250e-01 -8.44500e-01  7.24000e-01 -3.90000e-02\n",
      " -8.56750e-01 -8.28750e-01 -7.23500e-01  1.11000e-01  1.25950e+00\n",
      " -3.08500e-01 -2.14325e+00 -7.00250e-01 -1.12500e-01 -9.00500e-01\n",
      " -8.91250e-01 -3.34000e-01  2.70500e-01  1.20075e+00  5.66000e-01\n",
      " -1.36900e+00  3.18250e-01 -4.32250e-01 -9.56250e-01 -1.87775e+00\n",
      " -1.11375e+00  4.33250e-01  3.03200e+00  3.80750e-01 -4.70750e-01\n",
      " -3.47750e-01 -6.65000e-02 -6.72250e-01 -6.75000e-01  6.16250e-01\n",
      " -7.65750e-01 -7.85000e-01  3.93750e-01  1.97925e+00  1.19025e+00\n",
      "  1.21425e+00 -1.86750e-01 -4.80750e-01 -3.64500e-01  1.08450e+00\n",
      " -1.59000e-01  1.29875e+00 -2.62500e-01 -3.87500e-02 -4.43500e-01\n",
      " -7.57250e-01 -2.33750e-01 -1.71750e-01  3.80000e-02 -1.11525e+00\n",
      "  8.12250e-01  6.70250e-01 -1.11450e+00  7.12750e-01  3.51750e-01\n",
      " -2.99000e-01  1.25000e-03  2.72000e-01 -1.78225e+00  1.20600e+00\n",
      "  1.10400e+00 -6.06250e-01  5.25750e-01 -1.01675e+00 -1.97125e+00\n",
      " -1.40500e-01  6.24250e-01 -1.48425e+00  3.67250e-01  7.32250e-01\n",
      " -3.58500e-01 -2.16000e-01 -8.84500e-01 -7.77500e-01 -5.00750e-01\n",
      "  5.12250e-01  1.82750e-01 -9.95750e-01  5.03000e-01  7.62500e-02\n",
      "  1.16750e-01  6.86750e-01 -1.08000e-01 -4.75000e-02  2.65000e-01\n",
      " -5.50750e-01 -1.21250e-01  3.90750e-01 -9.56000e-01 -9.91000e-01\n",
      " -2.45750e-01  1.52750e-01  5.96000e-01  8.17500e-02  3.81750e-01\n",
      " -1.81250e-01 -5.26500e-01  7.94750e-01 -2.05000e-01  9.75750e-01\n",
      "  9.19500e-01  1.11250e-01  4.12250e-01 -2.15150e+00 -8.97750e-01\n",
      "  7.19000e-01  6.81000e-01  1.09525e+00 -1.12500e-01  2.08750e-01\n",
      " -1.17500e-01 -6.31000e-01  7.61750e-01 -7.47750e-01  4.60750e-01\n",
      " -3.16500e-01  4.80000e-02  1.33125e+00  6.50250e-01  2.72000e-01\n",
      "  2.76000e-01  6.26000e-01 -1.39100e+00 -6.82500e-02  2.63500e-01\n",
      " -2.36250e-01 -1.17125e+00  1.00375e+00  7.67000e-01 -3.33000e-01\n",
      " -5.35000e-01 -3.78750e-01 -2.22000e-01  8.16250e-01  4.49000e-01\n",
      "  5.88500e-01 -7.98500e-01  5.33000e-01  6.28500e-01 -1.29600e+00\n",
      "  1.21500e+00  1.53000e-01  1.24500e-01  6.43250e-01 -1.07800e+00\n",
      "  5.52250e-01  1.77450e+00  9.79750e-01 -1.78000e+00  2.19850e+00\n",
      " -1.77000e-01 -4.70250e-01 -7.81500e-01 -7.93000e-01  7.10000e-01\n",
      "  2.93750e-01 -6.71000e-01 -3.44500e-01  8.89000e-01  5.31000e-01\n",
      " -4.02500e-02  3.02500e-02 -5.04250e-01  3.77000e-01 -4.61500e-01\n",
      " -2.10250e-01 -1.15475e+00  4.72500e-01  3.62500e-02 -1.38300e+00\n",
      "  1.68225e+00  6.77500e-02 -5.26500e-01 -7.51500e-01 -9.27750e-01\n",
      " -1.39300e+00 -4.26250e-01 -1.11250e-01  7.23000e-01 -5.21750e-01\n",
      " -8.31250e-01 -5.05000e-01 -9.67500e-01  2.15500e-01  1.01250e+00\n",
      " -5.25000e-01  6.78750e-01  5.07000e-01  2.65000e-01  3.62500e-01\n",
      "  1.40750e-01 -1.25425e+00  9.97500e-01 -4.24750e-01  5.67500e-02\n",
      "  1.44775e+00  1.67500e-01 -4.24250e-01 -4.91000e-01  6.37500e-01\n",
      "  1.56750e-01  2.74000e-01]\n",
      "------------------------------\n",
      "Saved all Haar LWT coefficients (in columns) to: ./haar_lwt_1D_L3_coeffs_speed_dataset.csv\n",
      "Saved coefficients to directory: .//haar_lwt_1D_L3_coeffs_speed_dataset.csv\n",
      "------------------------------\n",
      "\n",
      "--- Reconstruction Results ---\n",
      "Reconstructed Data: [7.343 8.013 8.293 ... 9.517 9.46  9.309]\n",
      "Is Reconstruction Accurate? True\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def haar_lwt_1d_decompose(data):\n",
    "    \"\"\"\n",
    "    Performs a single level 1D Haar Lifting Wavelet Transform decomposition.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): The 1D input data array.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - approximation (np.ndarray): The approximation coefficients.\n",
    "            - detail (np.ndarray): The detail coefficients.\n",
    "            - original_len (int): The original length of the input data before padding.\n",
    "    \"\"\"\n",
    "    original_len = len(data)\n",
    "    \n",
    "    # Pad if length is odd to ensure even split\n",
    "    if original_len % 2 != 0:\n",
    "        padded_data = np.pad(data, (0, 1), 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data = data\n",
    "\n",
    "    # Split: Separate into even and odd indexed samples\n",
    "    even = padded_data[::2]\n",
    "    odd = padded_data[1::2]\n",
    "\n",
    "    # Predict: Calculate detail coefficients (d_j = odd - even)\n",
    "    detail = odd - even\n",
    "\n",
    "    # Update: Calculate approximation coefficients (s_j = even + d_j / 2)\n",
    "    approximation = even + detail / 2\n",
    "\n",
    "    return approximation, detail, original_len\n",
    "\n",
    "def haar_lwt_1d_reconstruct(approximation, detail, original_len):\n",
    "    \"\"\"\n",
    "    Reconstructs a 1D signal from its single level Haar Lifting Wavelet Transform coefficients.\n",
    "\n",
    "    Args:\n",
    "        approximation (np.ndarray): The approximation coefficients.\n",
    "        detail (np.ndarray): The detail coefficients.\n",
    "        original_len (int): The original length of the signal before decomposition padding.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The reconstructed 1D signal.\n",
    "    \"\"\"\n",
    "    # Inverse Update\n",
    "    even = approximation - detail / 2\n",
    "\n",
    "    # Inverse Predict\n",
    "    odd = detail + even\n",
    "\n",
    "    # Merge: Interleave even and odd parts\n",
    "    combined_padded_len = len(even) + len(odd)\n",
    "    reconstructed = np.empty(combined_padded_len, dtype=float)\n",
    "    reconstructed[::2] = even\n",
    "    reconstructed[1::2] = odd\n",
    "    \n",
    "    # Trim to original length\n",
    "    return reconstructed[:original_len]\n",
    "\n",
    "def _apply_1d_lwt_along_axis(data_nd, axis):\n",
    "    \"\"\"\n",
    "    Applies 1D Haar LWT decomposition along a specified axis of an N-dimensional array.\n",
    "\n",
    "    Args:\n",
    "        data_nd (np.ndarray): The N-dimensional input data array.\n",
    "        axis (int): The axis along which to apply the 1D transform.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - approx_coeffs_nd (np.ndarray): N-dimensional approximation coefficients.\n",
    "            - detail_coeffs_nd (np.ndarray): N-dimensional detail coefficients.\n",
    "            - original_len_axis (int): The original length of the specified axis before padding.\n",
    "    \"\"\"\n",
    "    original_shape = data_nd.shape\n",
    "    original_len_axis = original_shape[axis]\n",
    "\n",
    "    # Handle padding for N-D: If original_shape[axis] is odd, pad along that axis.\n",
    "    pad_width = [(0, 0)] * data_nd.ndim\n",
    "    if original_len_axis % 2 != 0:\n",
    "        pad_width[axis] = (0, 1)\n",
    "        padded_data_nd = np.pad(data_nd, pad_width, 'constant', constant_values=0)\n",
    "    else:\n",
    "        padded_data_nd = data_nd\n",
    "\n",
    "    # Get even and odd slices along the specified axis\n",
    "    slicer_even = [slice(None)] * padded_data_nd.ndim\n",
    "    slicer_even[axis] = np.arange(0, padded_data_nd.shape[axis], 2)\n",
    "    even_part = padded_data_nd[tuple(slicer_even)]\n",
    "\n",
    "    slicer_odd = [slice(None)] * padded_data_nd.ndim\n",
    "    slicer_odd[axis] = np.arange(1, padded_data_nd.shape[axis], 2)\n",
    "    odd_part = padded_data_nd[tuple(slicer_odd)]\n",
    "\n",
    "    # Predict: detail = odd - even\n",
    "    detail_coeffs_nd = odd_part - even_part\n",
    "\n",
    "    # Update: approximation = even + detail / 2\n",
    "    approx_coeffs_nd = even_part + detail_coeffs_nd / 2\n",
    "\n",
    "    return approx_coeffs_nd, detail_coeffs_nd, original_len_axis\n",
    "\n",
    "def _apply_1d_inverse_lwt_along_axis(approx_coeffs_nd, detail_coeffs_nd, axis, original_len_axis):\n",
    "    \"\"\"\n",
    "    Applies 1D Haar LWT reconstruction along a specified axis of N-dimensional approximation and detail coefficients.\n",
    "\n",
    "    Args:\n",
    "        approx_coeffs_nd (np.ndarray): N-dimensional approximation coefficients.\n",
    "        detail_coeffs_nd (np.ndarray): N-dimensional detail coefficients.\n",
    "        axis (int): The axis along which to apply the 1D inverse transform.\n",
    "        original_len_axis (int): The original length of the axis before decomposition padding.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The reconstructed N-dimensional array.\n",
    "    \"\"\"\n",
    "    # Inverse Update: even = approx - detail / 2\n",
    "    even_part = approx_coeffs_nd - detail_coeffs_nd / 2\n",
    "\n",
    "    # Inverse Predict: odd = detail + even\n",
    "    odd_part = detail_coeffs_nd + even_part\n",
    "\n",
    "    # Merge: Interleave even and odd parts\n",
    "    # Determine the shape of the reconstructed array before trimming\n",
    "    reconstructed_shape = list(even_part.shape)\n",
    "    reconstructed_shape[axis] = even_part.shape[axis] + odd_part.shape[axis]\n",
    "    reconstructed_padded_nd = np.empty(reconstructed_shape, dtype=float)\n",
    "\n",
    "    # Place even parts at even indices and odd parts at odd indices along the axis\n",
    "    slicer_even_out = [slice(None)] * reconstructed_padded_nd.ndim\n",
    "    slicer_even_out[axis] = np.arange(0, reconstructed_padded_nd.shape[axis], 2)\n",
    "    reconstructed_padded_nd[tuple(slicer_even_out)] = even_part\n",
    "\n",
    "    slicer_odd_out = [slice(None)] * reconstructed_padded_nd.ndim\n",
    "    slicer_odd_out[axis] = np.arange(1, reconstructed_padded_nd.shape[axis], 2)\n",
    "    reconstructed_padded_nd[tuple(slicer_odd_out)] = odd_part\n",
    "\n",
    "    # Trim to the original length along the specified axis\n",
    "    trim_slicer = [slice(None)] * reconstructed_padded_nd.ndim\n",
    "    trim_slicer[axis] = slice(0, original_len_axis)\n",
    "    \n",
    "    return reconstructed_padded_nd[tuple(trim_slicer)]\n",
    "\n",
    "def haar_lwt_nd_decompose(data, level):\n",
    "    \"\"\"\n",
    "    Performs an N-level N-dimensional Haar Lifting Wavelet Transform decomposition.\n",
    "\n",
    "    Args:\n",
    "        data (np.ndarray): The N-dimensional input data array.\n",
    "        level (int): The number of decomposition levels to perform.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing:\n",
    "              - 'original_shape': tuple, original shape of the input data.\n",
    "              - 'final_approx': np.ndarray, the final approximation sub-band (all Ls).\n",
    "              - 'level_X_details': dict, where X is the level number.\n",
    "                - Keys are sub-band names (e.g., 'LH', 'HL', 'HH' for 2D, or 'LLH', 'LHL', etc. for 3D).\n",
    "                  The name is a string of 'L' and 'H' characters, where 'L' means low-pass\n",
    "                  and 'H' means high-pass along the corresponding dimension. The order of characters\n",
    "                  corresponds to the order of dimensions (axis 0, axis 1, ...).\n",
    "                - Values are np.ndarray, the coefficient arrays for that sub-band.\n",
    "              - 'level_X_input_shapes_before_axis_transform': dict.\n",
    "                - Keys are the prefixes (L/H combinations) of the sub-bands *before* a 1D transform\n",
    "                  was applied along a specific axis.\n",
    "                - Values are the full N-dimensional shape of that sub-band *before* the 1D transform.\n",
    "                  This is crucial for reconstruction.\n",
    "    \"\"\"\n",
    "    current_approx = np.array(data, dtype=float)\n",
    "    coeffs_tree = {'original_shape': data.shape}\n",
    "    \n",
    "    ndim = data.ndim\n",
    "\n",
    "    for l in range(1, level + 1):\n",
    "        details_this_level = {}\n",
    "        # Stores the shape of the array that was input to the 1D transform along each axis.\n",
    "        # Key: The L/H prefix of the sub-band *before* the current axis was processed.\n",
    "        # Value: The shape of that sub-band.\n",
    "        level_l_input_shapes_before_axis_transform = {}\n",
    "\n",
    "        current_set_of_arrays = {'': current_approx} # Start with empty prefix for the initial array\n",
    "        \n",
    "        # Iterate through each dimension (axis)\n",
    "        for dim_idx in range(ndim):\n",
    "            next_set_of_arrays = {}\n",
    "            \n",
    "            # Iterate through the arrays accumulated from previous dimension transforms\n",
    "            for input_prefix, arr_to_process in current_set_of_arrays.items():\n",
    "                if arr_to_process.size == 0: # Skip empty arrays if they resulted from previous padding\n",
    "                    continue\n",
    "\n",
    "                # Store the shape of the array *before* applying 1D LWT along this dim_idx\n",
    "                # The key here is the prefix *leading up to* this dimension.\n",
    "                # This shape is needed for reconstruction.\n",
    "                level_l_input_shapes_before_axis_transform[input_prefix] = arr_to_process.shape\n",
    "\n",
    "                # Apply 1D LWT along the current dimension\n",
    "                approx_part, detail_part, _ = _apply_1d_lwt_along_axis(arr_to_process, dim_idx) # _ is original_len_axis\n",
    "                \n",
    "                # Store the approximation and detail parts with updated prefixes\n",
    "                next_set_of_arrays[input_prefix + 'L'] = approx_part\n",
    "                next_set_of_arrays[input_prefix + 'H'] = detail_part\n",
    "            \n",
    "            # Update the set of arrays for the next dimension's processing\n",
    "            current_set_of_arrays = next_set_of_arrays\n",
    "        \n",
    "        # After processing all dimensions for this level, `current_set_of_arrays`\n",
    "        # contains all 2^ndim sub-bands.\n",
    "        # The 'L'*ndim key holds the approximation for the next level.\n",
    "        current_approx = current_set_of_arrays.pop('L' * ndim)\n",
    "        \n",
    "        # The remaining items in `current_set_of_arrays` are the detail sub-bands for this level.\n",
    "        details_this_level = current_set_of_arrays\n",
    "\n",
    "        coeffs_tree[f'level_{l}_details'] = details_this_level\n",
    "        coeffs_tree[f'level_{l}_input_shapes_before_axis_transform'] = level_l_input_shapes_before_axis_transform\n",
    "        \n",
    "        # Check if the approximation sub-band is too small for further decomposition\n",
    "        if any(s < 2 for s in current_approx.shape) or current_approx.size == 0:\n",
    "            print(f\"Warning: Stopped N-D decomposition at level {l} because approximation sub-band became too small: {current_approx.shape}\")\n",
    "            break\n",
    "    \n",
    "    coeffs_tree['final_approx'] = current_approx\n",
    "    return coeffs_tree\n",
    "\n",
    "def haar_lwt_nd_reconstruct(coeffs_tree):\n",
    "    \"\"\"\n",
    "    Reconstructs an N-dimensional signal from its N-level Haar Lifting Wavelet Transform coefficients.\n",
    "\n",
    "    Args:\n",
    "        coeffs_tree (dict): A dictionary containing the final approximation sub-band\n",
    "                            and all detail sub-bands (LH, HL, HH, etc.) for each level,\n",
    "                            as returned by `haar_lwt_nd_decompose`.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The reconstructed N-dimensional signal.\n",
    "    \"\"\"\n",
    "    current_reconstruction = coeffs_tree['final_approx']\n",
    "    original_full_shape = coeffs_tree['original_shape']\n",
    "    ndim = len(original_full_shape)\n",
    "\n",
    "    # Determine the number of levels from the keys in coeffs_tree\n",
    "    levels = 0\n",
    "    for key in coeffs_tree:\n",
    "        if key.startswith('level_') and key.endswith('_details'):\n",
    "            levels = max(levels, int(key.split('_')[1]))\n",
    "    \n",
    "    # Reconstruct level by level, from coarsest to finest\n",
    "    for l in range(levels, 0, -1):\n",
    "        details_this_level = coeffs_tree[f'level_{l}_details']\n",
    "        input_shapes_before_axis_transform = coeffs_tree[f'level_{l}_input_shapes_before_axis_transform']\n",
    "\n",
    "        # Start with all 2^ndim sub-bands for this level, including the current_reconstruction (LL...L)\n",
    "        all_sub_bands_at_this_level = details_this_level.copy()\n",
    "        all_sub_bands_at_this_level['L' * ndim] = current_reconstruction\n",
    "\n",
    "        # Iterate through dimensions in reverse order for reconstruction\n",
    "        for dim_idx in range(ndim - 1, -1, -1):\n",
    "            next_reconstructed_arrays = {}\n",
    "            \n",
    "            # Generate all possible prefixes for the dimensions *before* dim_idx (L/H combinations)\n",
    "            prefix_combinations = [''.join(p) for p in product('LH', repeat=dim_idx)]\n",
    "            # Suffixes for dimensions *after* dim_idx, which have already been reconstructed ('R' combinations)\n",
    "            reconstruct_suffix_combinations = [''.join(p) for p in product('R', repeat=(ndim - 1 - dim_idx))]\n",
    "\n",
    "            for p_before in prefix_combinations:\n",
    "                for r_suffix in reconstruct_suffix_combinations:\n",
    "                    approx_key = p_before + 'L' + r_suffix\n",
    "                    detail_key = p_before + 'H' + r_suffix\n",
    "                    \n",
    "                    if approx_key in all_sub_bands_at_this_level and detail_key in all_sub_bands_at_this_level:\n",
    "                        approx_part = all_sub_bands_at_this_level[approx_key]\n",
    "                        detail_part = all_sub_bands_at_this_level[detail_key]\n",
    "                        \n",
    "                        # The prefix used when this `dim_idx` was processed in the forward pass\n",
    "                        # is simply `p_before`.\n",
    "                        input_prefix_for_lookup = p_before\n",
    "                        \n",
    "                        original_input_shape_for_this_dim = input_shapes_before_axis_transform.get(input_prefix_for_lookup)\n",
    "\n",
    "                        if original_input_shape_for_this_dim is None:\n",
    "                            raise KeyError(f\"Original input shape not found for (dim_idx={dim_idx}, input_prefix='{input_prefix_for_lookup}') at level {l}. \"\n",
    "                                           f\"Approx key: '{approx_key}', Detail key: '{detail_key}'\")\n",
    "\n",
    "                        original_len_for_this_axis = original_input_shape_for_this_dim[dim_idx]\n",
    "\n",
    "                        reconstructed_part = _apply_1d_inverse_lwt_along_axis(\n",
    "                            approx_part, detail_part, dim_idx, original_len_for_this_axis\n",
    "                        )\n",
    "                        \n",
    "                        # The key for the next level of reconstruction is `p_before + 'R' + r_suffix`\n",
    "                        # This key needs to be consistent for the next iteration of dim_idx.\n",
    "                        # The 'R' for the current dim_idx is added here.\n",
    "                        next_reconstructed_arrays[p_before + 'R' + r_suffix] = reconstructed_part\n",
    "            \n",
    "            # CRITICAL FIX: Update all_sub_bands_at_this_level for the next dimension's processing\n",
    "            all_sub_bands_at_this_level = next_reconstructed_arrays\n",
    "        \n",
    "        # After all dimensions are reconstructed for this level, there should be only one array left\n",
    "        # which is the full approximation for the previous level.\n",
    "        current_reconstruction = all_sub_bands_at_this_level['R' * ndim]\n",
    "    \n",
    "    # Final trim to the original input data shape\n",
    "    final_reconstruction_slicer = tuple(slice(0, s) for s in original_full_shape)\n",
    "    return current_reconstruction[final_reconstruction_slicer]\n",
    "\n",
    "\n",
    "def save_coefficients_to_files(output_dir, coeffs_tree, filename='all_haar_lwt_coeffs_columns_nd.csv'):\n",
    "    \"\"\"\n",
    "    Saves all Haar LWT coefficients (approximation and all detail levels) into a single .csv file,\n",
    "    with each coefficient type in its own column. Handles N-dimensional data.\n",
    "\n",
    "    Args:\n",
    "        output_dir (str): The directory where the coefficient file will be saved.\n",
    "                          If the directory does not exist, it will be created.\n",
    "        coeffs_tree (dict): A dictionary containing the final approximation sub-band\n",
    "                            and all detail sub-bands for each level,\n",
    "                            as returned by `haar_lwt_nd_decompose`.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    all_coeff_arrays_flat = []\n",
    "    headers = []\n",
    "\n",
    "    # Add the final approximation (LL...L)\n",
    "    if 'final_approx' in coeffs_tree:\n",
    "        all_coeff_arrays_flat.append(coeffs_tree['final_approx'].flatten())\n",
    "        headers.append('Final_Approximation')\n",
    "\n",
    "    # Determine the number of levels and dimensions\n",
    "    levels = 0\n",
    "    ndim = len(coeffs_tree['original_shape'])\n",
    "    for key in coeffs_tree:\n",
    "        if key.startswith('level_') and key.endswith('_details'):\n",
    "            levels = max(levels, int(key.split('_')[1]))\n",
    "\n",
    "    # Generate all possible L/H combinations for N dimensions\n",
    "    all_lh_combinations = [''.join(p) for p in product('LH', repeat=ndim)]\n",
    "    \n",
    "    # Exclude the 'L'*ndim combination as it's the approximation for the next level\n",
    "    # or the final_approx.\n",
    "    detail_lh_combinations = [c for c in all_lh_combinations if c != 'L' * ndim]\n",
    "\n",
    "    # Add detail coefficients for each level\n",
    "    for l in range(1, levels + 1):\n",
    "        details_this_level = coeffs_tree.get(f'level_{l}_details', {})\n",
    "        # Sort detail combinations for consistent column order in CSV\n",
    "        for combo in sorted(detail_lh_combinations):\n",
    "            if combo in details_this_level and details_this_level[combo].size > 0:\n",
    "                all_coeff_arrays_flat.append(details_this_level[combo].flatten())\n",
    "                headers.append(f'{combo}_L{l}')\n",
    "\n",
    "    # Find the maximum length among all flattened coefficient arrays\n",
    "    max_len = 0\n",
    "    if all_coeff_arrays_flat:\n",
    "        max_len = max(len(arr) for arr in all_coeff_arrays_flat)\n",
    "\n",
    "    # Pad shorter arrays with NaN\n",
    "    padded_coeff_arrays = []\n",
    "    for arr in all_coeff_arrays_flat:\n",
    "        if len(arr) < max_len:\n",
    "            padded_arr = np.pad(arr, (0, max_len - len(arr)), 'constant', constant_values=np.nan)\n",
    "        else:\n",
    "            padded_arr = arr\n",
    "        padded_coeff_arrays.append(padded_arr)\n",
    "\n",
    "    # Stack the padded arrays horizontally\n",
    "    if padded_coeff_arrays:\n",
    "        combined_coeffs_2d = np.column_stack(padded_coeff_arrays)\n",
    "    else:\n",
    "        combined_coeffs_2d = np.array([[]])\n",
    "\n",
    "    header_str = ','.join(headers)\n",
    "\n",
    "    combined_filepath = os.path.join(output_dir, filename)\n",
    "    np.savetxt(combined_filepath, combined_coeffs_2d, delimiter=',', header=header_str, comments='')\n",
    "    print(f\"Saved all Haar LWT coefficients (in columns) to: {combined_filepath}\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    df = pd.read_csv('Data_August_Renewable.csv')\n",
    "    data = df['Speed'].values\n",
    "    n_levels = 3\n",
    "    print(f\"Original Data: {data}\")\n",
    "    print(f\"Decomposition Levels: {n_levels}\")\n",
    "    print(\"-\" * 30) \n",
    "    coeffs = haar_lwt_nd_decompose(data, n_levels)\n",
    "    print(\"\\n--- Decomposition Results ---\")\n",
    "    print(f\"Final LL (Approximation) Sub-band:\\n{coeffs['final_approx']}\")\n",
    "    for l in range(1, n_levels + 1):\n",
    "        details = coeffs.get(f'level_{l}_details', {})\n",
    "        for key, val in details.items():\n",
    "            print(f\"  {key}_L{l} Detail:\\n{val}\")\n",
    "    print(\"-\" * 30)\n",
    "    output_directory = './'\n",
    "    save_coefficients_to_files(output_directory, coeffs, filename='haar_lwt_1D_L3_coeffs_speed_dataset.csv')\n",
    "    print(f\"Saved coefficients to directory: {output_directory}/haar_lwt_1D_L3_coeffs_speed_dataset.csv\")\n",
    "    print(\"-\" * 30)\n",
    "    reconstructed_data = haar_lwt_nd_reconstruct(coeffs)\n",
    "    print(\"\\n--- Reconstruction Results ---\")\n",
    "    print(f\"Reconstructed Data: {reconstructed_data}\")\n",
    "    is_reconstruction_accurate = np.allclose(data, reconstructed_data)\n",
    "    print(f\"Is Reconstruction Accurate? {is_reconstruction_accurate}\")\n",
    "    if not is_reconstruction_accurate:\n",
    "        print(f\"Difference: {data - reconstructed_data}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # # --- 1D Example (still works with the new N-D functions) ---\n",
    "    # print(\"--- 1D Example ---\")\n",
    "    # data_1d = np.array([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
    "    # n_levels_1d = 2\n",
    "\n",
    "    # print(f\"Original 1D Data: {data_1d}\")\n",
    "    # print(f\"Decomposition Levels: {n_levels_1d}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # coeffs_1d = haar_lwt_nd_decompose(data_1d, n_levels_1d)\n",
    "    # print(\"\\n--- 1D Decomposition Results ---\")\n",
    "    # print(f\"Final LL (Approximation) Sub-band:\\n{coeffs_1d['final_approx']}\")\n",
    "    # for l in range(1, n_levels_1d + 1):\n",
    "    #     details = coeffs_1d.get(f'level_{l}_details', {})\n",
    "    #     for key, val in details.items():\n",
    "    #         print(f\"  {key}_L{l} Detail:\\n{val}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # output_directory_1d = 'haar_lwt_coeffs_1d'\n",
    "    # save_coefficients_to_files(output_directory_1d, coeffs_1d)\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # reconstructed_data_1d = haar_lwt_nd_reconstruct(coeffs_1d)\n",
    "    # print(\"\\n--- 1D Reconstruction Results ---\")\n",
    "    # print(f\"Reconstructed Data: {reconstructed_data_1d}\")\n",
    "    # is_reconstruction_accurate_1d = np.allclose(data_1d, reconstructed_data_1d)\n",
    "    # print(f\"Is 1D Reconstruction Accurate? {is_reconstruction_accurate_1d}\")\n",
    "    # if not is_reconstruction_accurate_1d:\n",
    "    #     print(f\"Difference: {data_1d - reconstructed_data_1d}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "\n",
    "    # # --- 2D Example ---\n",
    "    # print(\"\\n--- 2D Example ---\")\n",
    "    # data_2d = np.array([\n",
    "    #     [1, 2, 3, 4, 5],\n",
    "    #     [6, 7, 8, 9, 10],\n",
    "    #     [11, 12, 13, 14, 15],\n",
    "    #     [16, 17, 18, 19, 20],\n",
    "    #     [21, 22, 23, 24, 25]\n",
    "    # ])\n",
    "    # n_levels_2d = 2\n",
    "\n",
    "    # print(f\"Original 2D Data:\\n{data_2d}\")\n",
    "    # print(f\"Original 2D Data Shape: {data_2d.shape}\")\n",
    "    # print(f\"Decomposition Levels: {n_levels_2d}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # coeffs_2d = haar_lwt_nd_decompose(data_2d, n_levels_2d)\n",
    "\n",
    "    # print(\"\\n--- 2D Decomposition Results ---\")\n",
    "    # print(f\"Final LL (Approximation) Sub-band:\\n{coeffs_2d['final_approx']}\")\n",
    "    # for l in range(1, n_levels_2d + 1):\n",
    "    #     details = coeffs_2d.get(f'level_{l}_details', {})\n",
    "    #     # Sort keys for predictable output\n",
    "    #     for key in sorted(details.keys()):\n",
    "    #         val = details[key]\n",
    "    #         print(f\"  {key}_L{l} Detail:\\n{val}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # output_directory_2d = 'haar_lwt_coeffs_2d'\n",
    "    # save_coefficients_to_files(output_directory_2d, coeffs_2d)\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # reconstructed_data_2d = haar_lwt_nd_reconstruct(coeffs_2d)\n",
    "\n",
    "    # print(\"\\n--- 2D Reconstruction Results ---\")\n",
    "    # print(f\"Reconstructed Data:\\n{reconstructed_data_2d}\")\n",
    "    # is_reconstruction_accurate_2d = np.allclose(data_2d, reconstructed_data_2d)\n",
    "    # print(f\"Is 2D Reconstruction Accurate? {is_reconstruction_accurate_2d}\")\n",
    "    # if not is_reconstruction_accurate_2d:\n",
    "    #     print(f\"Difference:\\n{data_2d - reconstructed_data_2d}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # # --- 3D Example ---\n",
    "    # print(\"\\n--- 3D Example ---\")\n",
    "    # data_3d = np.arange(1, 28).reshape((3, 3, 3)) # A 3x3x3 array\n",
    "    # n_levels_3d = 1 # For 3x3x3, only 1 level is practical as dimensions become 2x2x2 after 1 level\n",
    "\n",
    "    # print(f\"Original 3D Data:\\n{data_3d}\")\n",
    "    # print(f\"Original 3D Data Shape: {data_3d.shape}\")\n",
    "    # print(f\"Decomposition Levels: {n_levels_3d}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # coeffs_3d = haar_lwt_nd_decompose(data_3d, n_levels_3d)\n",
    "\n",
    "    # print(\"\\n--- 3D Decomposition Results ---\")\n",
    "    # print(f\"Final LLL (Approximation) Sub-band:\\n{coeffs_3d['final_approx']}\")\n",
    "    # for l in range(1, n_levels_3d + 1):\n",
    "    #     details = coeffs_3d.get(f'level_{l}_details', {})\n",
    "    #     # Sort keys for predictable output\n",
    "    #     for key in sorted(details.keys()):\n",
    "    #         val = details[key]\n",
    "    #         print(f\"  {key}_L{l} Detail:\\n{val}\")\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # output_directory_3d = 'haar_lwt_coeffs_3d'\n",
    "    # save_coefficients_to_files(output_directory_3d, coeffs_3d)\n",
    "    # print(\"-\" * 30)\n",
    "\n",
    "    # reconstructed_data_3d = haar_lwt_nd_reconstruct(coeffs_3d)\n",
    "\n",
    "    # print(\"\\n--- 3D Reconstruction Results ---\")\n",
    "    # print(f\"Reconstructed Data:\\n{reconstructed_data_3d}\")\n",
    "    # is_reconstruction_accurate_3d = np.allclose(data_3d, reconstructed_data_3d)\n",
    "    # print(f\"Is 3D Reconstruction Accurate? {is_reconstruction_accurate_3d}\")\n",
    "    # if not is_reconstruction_accurate_3d:\n",
    "    #     print(f\"Difference:\\n{data_3d - reconstructed_data_3d}\")\n",
    "    # print(\"-\" * 30)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Normal_app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
